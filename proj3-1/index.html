<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;

    letter-spacing: 1px;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }


  #comparisonTable th {
  background-color: rgb(197, 215, 249);
  }

/* 
  #comparisonTable table, td, th {  
    border: 1px solid #ddd;
    text-align: left;
  } */

  #comparisonTable table {
    border: 1px solid #ddd;
    text-align: left;

    border-collapse: collapse;
    width: 100%;
  }

  #comparisonTable th {
    border: 1px solid #ddd;
    text-align: left;
    padding: 15px;
  } 

  #comparisonTable td {
    border: 1px solid #ddd;
    text-align: left;
    padding: 15px;
  } 

</style>
<title>CS 184 Path Tracer 1</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Zhihan Cheng, Yuerou Tang</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="https://cal-cs184-student.github.io/project-webpages-sp23-qs/proj3-1/index.html">https://cal-cs184-student.github.io/project-webpages-sp23-qs/proj3-1/index.html</a></h2>

<br><br>


<div align="center">

  <img src="images/ultimateBunny.png" width="480px" />
  <figcaption align="middle">my bunny is the bounciest bunny</figcaption>
</div>

<br>


<h2 align="middle">Overview</h2>
<p>
    In this project, we implemented ray tracing methods. We started from constructing BVH, a data structure that allows us to compute ray intersection with objects
    faster. We then first implemeneted direct lighting, which are lights that directly come from a light source. Then we implemented one bounce illumination, which 
    are the lights that bounce off from other objects. We also implemented Russian Roulette and Adaptive sampling to enable more efficient rendering.  
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Ray Generation
</h3>
<p>
  The <code>Camera::generate_ray(...)</code> function takes in (x, y) in image coordinates and output a ray with origin and direction in the world space. 
    
  To do this, we first compute a i2c matrix that transfer a homogenous 2D coordinates in image space to a homogenous 2D coordinates in the camera space.
  The i2c matrix is defined so that bottom left corner, $(0, 0)$, transfers to $(-tan(\frac{hFov}{2}), -tan(\frac{vFov}{2})) $, 
  and the upper right corner, $(1, 1)$, transfers to $(tan(\frac{hFov}{2}), tan(\frac{vFov}{2})) $.
  Since in the camera space, the z coordinates is always -1, we set the z axis of our point to -1, after applying i2c, transforming it into camera space.
  <br>
  We then generate the ray with the camera position in the world space as origin 
  and with direction pointing from $(0, 0, 0)$ to our point in camera space normalized and transformed into the world space.
  <br>
  We also set the max_t and min_t of the ray.

  <br>
  <br>

  The <code>PathTacer::raytrace_pixel</code> function is used to estimate the radiance at each pixel. 
  To achieve this, we first generate ns_aa number of rays that originate at the camera and passes through the pixel at the given point with some random offset on an image.
  We use the <code>Camera::generate_ray(...)</code> function to do so. 
  We follow each ray to estimate the radiance.
  We sum all radiances and store the average value into sampleBuffer.

  <br>
  <br>

</p>

<h3>
  Ray Intersection with Triangles
</h3>
<p>

    To test intersection with triangle, we solve for time t when ray intersects with the plane in which the triangle lies. The intersection is only valid when the following two conditions is met: 

    <ol>
      <li>Time t for point of intersection must be greater than 0.</li>
      <li>Point of intersection must be within the triangle itself. We use barycentric coordinates to test this. If $(\alpha, \beta, \gamma)$ are all within 0 to 1, the intersection is valid. </li>
    </ol>
    
    We used the MÃ¶ller-Trumbore Algorithm. This algorithm solves the function: $\vec{O} + t\vec{D} = (1 - b1 - b2)\vec{P_0} + b1\vec{P_1} + b2\vec{P_2}$. 
    It is an optimized way to test for whether the intersection is within the triangle without first calculating the plane eqution. 

    
</p>
<br>

<h3>
  Ray Intersection with Spheres
</h3>
<p>
  
    To test intersection with spheres, we solve for time t when ray intersects the sphere. We solve the quadratic function, and there're three possible outcomes: 

    <ol>
      <li>There's no solution. This means that the ray does not intersect with the sphere.</li>
      <li>There's one solution. This means that the ray is tangent to the sphere.</li>
      <li>There're two solutions. If both t are greater than 0, we have two intersections with the sphere.</li>
    </ol>

</p>
<br>

<h3>
  Images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part1/CBempty.png" align="middle" width="400px"/>
        <figcaption>Empty Room</figcaption>
      </td>
      <td>
        <img src="images/part1/CBspheres.png" align="middle" width="400px"/>
        <figcaption>Spheres with normal shading</figcaption>
      </td>
    </tr>
    <!-- <tr align="center">
      <td>
        <img src="images/part1/cow.png" align="middle" width="400px"/>
        <figcaption>Cow</figcaption>
      </td>
      <td>
        <img src="images/part1/bunny.png" align="middle" width="400px"/>
        <figcaption>example4.dae</figcaption>
      </td>
    </tr> -->
  </table>
</div>
<br>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  BVH construction algorithm & heuristic for picking the splitting point.
</h3>
<p>
    We build our BVH resursively. 
    Our algorithm partitions the primitives into two groups 
    and recursively applies the algorithm to each group until the number of primitives left is smaller than maximum_leaf_size. 

    We always choose the split primitives along the axis with the largest range difference. 
    In this way, we will most effeciently decrease the range of the bounding box for the BVHNode in next level. 

    The group that each primitives belong to is determined by comparing each primitive's centroid to the mean centroid of all primitives.
    If the primitive centroid is smaller than the mean centroid, the primitive belongs to the left group, otherwise, it belongs to the right.

    In each recursive call, we build a BVHNode. 
    A leaf BVHNode will store all primitives it contains, 
    while a non-leaf node stores left and right pointer to the BVHNode built on its left and right primitive groups.
</p>
<br>
<h3>
  Normal shading for large .dae files that can only be rendered with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part2/maxplanck.png" align="middle" width="400px"/>
        <figcaption>maxplanck.dae</figcaption>
      </td>
      <td>
        <img src="images/part2/CBlucy.png" align="middle" width="400px"/>
        <figcaption>CBLucy.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Comparison of rendering times on scenes with moderately complex geometries with and without BVH acceleration. 
</h3>

<div id="comparisonTable">
  <table>
    <tr>
      <th>Scene</th>
      <th>Without BVH</th>
      <th>With BVH</th>
    </tr>
    <tr>
      <td>Cow</td>
      <td>25.2083s</td>
      <td>0.1387s</td>
    </tr>
    <tr>
      <td>MaxPlanck</td>
      <td>219.0163s</td>
      <td>0.1730s</td>
    </tr>
    <tr>
      <td>CBLucy</td>
      <td>1330.6861s</td>
      <td>0.2100s</td>
    </tr>
  
  </table>
  
</div>

<br>

<p>
  As we can see, when rendering moderately complex scenes, using BVH acceleration can significantly reduce rendering times. 
  Without BVH acceleration, the render would need to test each primitive in the scene individually, leading to much longer rendering times. 
  With BVH acceleration, the hierarchy allows the render to more quickly determine which objects the ray could potentially intesect, reducing the number of tests needed and resulting in faster rendering times. 

  The speed up is most significant in scenes with higher complexity.
</p>

<br>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    Hemisphere sampling: To estimate how much light were reflected at the given intersetion 
    point (<code>hit_p</code>), we first estimate how much light arrived at the point. In this approach,
    we implemented it by uniformly sampling the hemisphere around <code>hit_p</code> to get the possible rays 
    that might hit the intersection (blue rays below in the illustration).
    <p align = "middle"><img src="./images/part4/4_illu.jpg" align="middle" width="400px"/></p>
    We then test if the ray intersects the scene. If it does, we have obtained the necessary components to calculate radiance from the intersection with this 
    formula:
    <p align = "middle"><img src="./images/part1/montecarla.png" align="middle" width="400px"/></p>
    where \(f_r\) is \(\frac{\rho}{\pi}\), \(L_i\) is the emission of the light source (since we're dealing with direct
    lighting), \(cos\theta_j\) is the angle between the sampled vector and the object surface normal, and \(p(w_j)\) is 
    the pdf of the sampled vector. Since we're sampling uniformly, it would be \(\frac{1}{2\pi}\) because the solid angle
    for a hemisphere would be \(2\pi\). </p>

    <p>
    Importance sampling: We still need to estimate how much light arrived at the point, but instead of uniformly sampling
    from a hemisphere, we instead will sample the light directly. <code>SceneLight::sample_L(Vector3D& p, Vector3D* wi, double* distToLight, double* pdf)</code>
    takes 1 sample, and returns the sampled ray (between the object and the light source direction), the sampled emittance, 
    distance from the object to the light source and the pdf of the sampled direction. We can then use the distance 
    from the object to the lightsource, and check if the ray intersects any surface in front of the light source within this range (between the light source
    and the object). If there is, then the light doesn't really cast any radiance to the object. If there isn't then we calculate
    radiance from that field with the same technique as above. 
  </p>
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="./images/part3/CBbunny_64_32_H.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae, s = 64, l = 32</CBbunny></figcaption>
      </td>
      <td>
        <img src="./images/part3/bunny_64_32.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae, s = 64, l = 32</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/part3/CBspheres_lambertian_H_64_32.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae, s = 64, l = 32</CBbunny></figcaption>
      </td>
      <td>
        <img src="./images/part3/CBspheres_lambertian_64_32.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae, s = 64, l = 32</figcaption>
      </td>
    </tr>
    <br>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/part3/CBbunny_1_1.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae, s = 1, l = 1</figcaption>
      </td>
      <td>
        <img src="./images/part3/CBbunny_1_4.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae, s = 1, l = 4</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/part3/CBbunny_1_16.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae, s = 1, l = 16</figcaption>
      </td>
      <td>
        <img src="./images/part3/CBbunny_1_64.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae, s = 1, l = 64</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
  Hemisphere sampling produced a more grainy result, and the details were not as good as importance sampling. There is also less noise on importance sampling result.
  This was very obvious in the background -- hemisphere sampling produced a coarse background, while importance sampling produced a smoother one. This could be due 
  to the fact that hemisphere sampling takes in vectors from all directions with equal weight, but only a few rays are contributing to the final radiance, while importance
  sampling weighted them with their probability. 
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
    We implemented the <code>PathTracer::at_least_one_bounce_radiance</code> function to achieve global illumination with ray bouncing multiple times in the scene. 
    We first account for cases where max_ray_depth is 0 or 1 in the <code>PathTracer::est_radiance_global_illumination</code> function. 
    Then, inside <code>PathTracer::at_least_one_bounce_radiance</code> function, we first calculate the onc_bounce_radiance at the hit point, and sample a direction and its corresponding next intersection point with 
    <code>DiffuseBSDF::sample_f</code>.
    <p align = "middle">
      <img src="images/part3/3_illu.jpg" align="middle" width="400px"/>

    </p>
    The next intersection is where light would bounce to, or come from, since in ray tracing, we are doing it backwards. 
    And then we check for conditions to continue the recursion:
    <ol>
      <li> max_ray_depth must be greater than 1.</li>
      <li> Russian Roulette has not terminated the bounce. Russian Roulette is done with coin_flip function with probabily 0.3 to prevent infinite recursion. </li>
    </ol>

    If both conditions are met, we call <code>PathTracer::at_least_one_bounce_radiance</code> function recursively on the newly initiated ray and next intersection point 
    and use the reflection function to add the next bounce radiance to current radiance.
</p>
<br>


<h3>
  Bunny scene rendered with global (direct and indirect) illumination, using 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part4/bunny/CBbunny_1024_1_1.png" align="middle" width="400px"/>
        <figcaption>Direct illumination of bunny.dae</figcaption>
      </td>
      <td>
        <img src="images/part4/bunny/CBbunny_1024_1_3.png" align="middle" width="400px"/>
        <figcaption>Global illumination of bunny.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  CBspheres_lambertian.dae scene, rendered with 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part4/illum/CBspheres_lambertian_1024_1_3_direct_illum.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination </figcaption>
      </td>
      <td>
        <img src="images/part4/illum/CBspheres_lambertian_1024_1_3_indirect_illum.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination </figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
  Direct illumination refers to light that comes directly from light sources and shines onto an object, 
  while indirect illumination refers to light that has bounced off other objects and illuminates an object indirectly.

  The scene above rendered with only direct illumination have very strong and defined shadows, 
  with objects that are not directly illuminated appearing very dark or even black. 
  The overall lighting in the scene is very dependent on the placement of the light sources. 

  <br>
  <br>
  
  On the other hand, the scene rendered with only indirect illumination have much softer shadows and a more diffused, natural lighting.
  The scene has a more diffused and natural lighting, as light bounces around the environment and illuminates objects from various angles. 
  
  
</p>
<br>

<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part4/bunny/CBbunny_1024_1_0.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/part4/bunny/CBbunny_1024_1_1.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part4/bunny/CBbunny_1024_1_2.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/part4/bunny/CBbunny_1024_1_3.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part4/bunny/CBbunny_1024_1_100.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
  The max_ray_depth parameter determines the maximum number of times that a light ray can bounce off surfaces in a scene before it is terminated. 
  When max_ray_depth is set to 0, the rendered view will only show the light source itself.
  And when max_ray_depth is set to 1, the rendered view shows only direct illumination.
  Then, as the value of max_ray_depth is increases, the rendered view gets brighter, as light rays bounce off surfaces in the scene more times.
  This leads to more diffuse lighting and softer shadows, as well as a greater sense of depth and realism in the scene.

  <br>
  <br>

  However, increasing max_ray_depth beyond a certain point can lead to diminishing returns, 
  as the effect of indirect illumination becomes less noticeable with each additional bounce. 
  In the above scene, the image rendered with max_ray_depth set to 3 and max_ray_depth set to 100 is already very similar.
  And the rendering process becomes significantly slower without a significant increase in visual quality.
  

</p>
<br>

<h3>
  CBspheres_lambertian.dae scene, rendered with 4 light rays and various sample-per-pixel rate.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part4/varying_l/CBspheres_lambertian_1_4_3.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel </figcaption>
      </td>
      <td>
        <img src="images/part4/varying_l/CBspheres_lambertian_2_4_3.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel </figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part4/varying_l/CBspheres_lambertian_4_4_3.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel </figcaption>
      </td>
      <td>
        <img src="images/part4/varying_l/CBspheres_lambertian_8_4_3.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel </figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part4/varying_l/CBspheres_lambertian_16_4_3.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel </figcaption>
      </td>
      <td>
        <img src="images/part4/varying_l/CBspheres_lambertian_64_4_3.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel </figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part4/varying_l/CBspheres_lambertian_1024_4_3.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel </figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
  The sample-per-pixel rate is the number of samples taken by the render for each pixel in the rendered image. 
  As we can observe from above, images get smoother and less noisier as we increase the sample-per-pixel rate. 
  This makes sense intuitively since as more samples are taken, lighting and material properties of the scene is better captured.


</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
    Adaptive sampling is when we don't sample all the pixels all the way to the maximum number of samples that we set. This is because some pixels coverges very fast,
    so we don't need to compute further samples after it converges. However, some other pixels might need more samples. The threshold that we used to determine if 
    a pixel needs further sampling is by checking whether \(I \leq maxTolerance * \mu\), where \(I = 1.96* \frac{\sigma}{\sqrt{n}}\). \(\mu = \frac{s1}{n}\), \(\sigma^2 = 
    \frac{1}{n-1}*(s_2-\frac{s1^2}{n})\), \(s_2 = \sum{x_k^2}\), \(s1= \sum{x_k}\). \(x_k\) is the illuminance of each sample. For every <code>samplesPerBatch</code>
    number of samples, we perform this check to see if the pixel has converged, and if so, we stop estimating the radiance for the pixel. 
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/part5/CBbunny_2048_1_5_adap.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
        <figcaption>s_max = 2048, l = 1, m = 5 </figcaption>
      </td>
      <td>
        <img src="./images/part5/CBbunny_2048_1_5_adap_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image CBbunny.dae</figcaption>
        <figcaption>s_max = 2048, l = 1, m = 5</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/part5/CBspheres_lambertian_2048_1_5_adap.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
        <figcaption>s_max = 2048, l = 1, m = 5</figcaption>
      </td>
      <td>
        <img src="images/part5/CBspheres_lambertian_2048_1_5_adap_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image CBspheres_lambertian.dae</figcaption>
        <figcaption>s_max = 2048, l = 1, m = 5</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
  As you can see, different areas now have different sampling rates. Red indicates high sampling rate, and blue indicates low sampling rate. 
</p>


</body>
</html>
