<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
  <style>
    body {
      background-color: white;
      padding: 100px;
      width: 1000px;
      margin: auto;
      text-align: left;
      font-weight: 300;
      font-family: 'Open Sans', sans-serif;
      color: #121212;

      letter-spacing: 1px;
    }

    h1,
    h2,
    h3,
    h4 {
      font-family: 'Source Sans Pro', sans-serif;
    }

    kbd {
      color: #121212;
    }


    #comparisonTable th {
      /* background-color: rgb(197, 215, 249); */
      background-color: rgb(247, 247, 247);
    }

    /* 
  #comparisonTable table, td, th {  
    border: 1px solid #ddd;
    text-align: left;
  } */

    #comparisonTable table {
      border: 1px solid #ddd;
      text-align: left;

      border-collapse: collapse;
      width: 100%;
    }

    #comparisonTable th {
      border: 1px solid #ddd;
      text-align: left;
      padding: 7px;
    }

    #comparisonTable td {
      border: 1px solid #ddd;
      text-align: left;
      padding: 7px;
    }
  </style>
  <title>CS 184 Final Project</title>
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

</head>


<body>

  <h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
  <h1 align="middle">Final Report: Sky, and Rainbow (or Halo?)</h1>
  <h2 align="middle">Yuerou Tang, Zhihan Cheng, Long He, Debby Lin</h2>

  <br>
  <!-- Add Website URL -->
  <!-- <h4>Proposal URL: <a href="https://cal-cs184-student.github.io/project-webpages-sp23-qs/final/proposal/proposal.html">https://cal-cs184-student.github.io/project-webpages-sp23-qs/final/proposal/proposal.html</a></h4>
<h4>Milestone URL: <a href="https://cal-cs184-student.github.io/project-webpages-sp23-qs/final/milestone/milestone.html">https://cal-cs184-student.github.io/project-webpages-sp23-qs/final/milestone/milestone.html</a></h4>

<h4>Presentation Slides: <a href="https://docs.google.com/presentation/d/1X-Q1tBVeLp8mKCGx8GPwmvqmqJyHFNyYadMLDevG_4E/edit?usp=sharing">https://docs.google.com/presentation/d/1X-Q1tBVeLp8mKCGx8GPwmvqmqJyHFNyYadMLDevG_4E/edit?usp=sharing</a></h4>
<h4>Video Link: <a href="https://drive.google.com/file/d/1FMtKwod_yaLLsnQnkDgIgp_s0AnwtQw5/view?usp=sharing">https://drive.google.com/file/d/1FMtKwod_yaLLsnQnkDgIgp_s0AnwtQw5/view?usp=sharing</a></h4> -->
<h4 align="middle">Video Link: <a href=" ">https://drive.google.com/file/d/1wFnEAqtGcXkU3kNMjnAy4wwc8KSx2WOK/view?usp=drivesdk</a></h4>
  <br><br>

  <!-- 
<div align="center">

  <img src="nishita_demo.png" width="480px" />
  <figcaption align="middle">Rendered Sky from Nishita et al., Siggraph 1993</figcaption>
</div> -->

  <!-- <br> -->

<p align = "middle">
  <img src="./gif.gif" align="middle" width="300px" />

</p>
  <h2 align="middle"> Abstract </h2>

  <p>
    Our group attempted to render scenes of sky and halos. 
    We rendered the sky using volume rendering with two different types of atmospheric scattering: Rayleigh and Mie. 
    We also delved into tone mapping to generate realistic images, and acceleration structure to real time sky rendering. 
    We further added the feature of rendering halos around the sun from physical computation and color mapping. We managed to provide fast rendering of the sky with different viewing perspectives as well as features of adding halos.
  </p>
  <h2 align="middle"> Model </h2>
  <p>
    The atmosphere model we'll be using in our final project is defined as two concentric spheres. 
    The center is always at (0, 0, 0). 

    The inner sphere represents the Earth. The Earth's radius is defined to be 6360 km.
    The outer sphere represents the atmosphere. The atmosphere radius is defined to be 6420 km. 

    We define the sun as being infinitely far away from us, so the sun light reaching the Earth is modeled as parraleled light. 
    The sun lies on the yz plane. 
    It's direction is specified by angel $\theta$, which is the angle between the sun and y axis.

    We are able to represent two kinds of images with this model. 
    <ul>
      <li>Fisheye</li>
      Fisheye images are rendered by specifying a camera location (Pc) and looking up from the camera at the sky. The image captures all 360 degree view.
      <li>Normal Camera</li>
      Normal camera images are rendered by specifying a camera location (Pc) with a FOV. We specify a plane on the z axis for our image, 
      and calculate the size of the image in world space by using the size of image we want to render and FOV of our camera.
    </ul>

    <br>
    <div align="middle">
      <table style="width:100%">
        <tr align="center">
          <td>
            <img src="./images/model/fisheye.jpeg" align="middle" width="260px" />
            <figcaption>Fisheye Camera</figcaption>
          </td>
          <td>
            <img src="./images/model/normal.jpeg" align="middle" width="340px" />
            <figcaption>Normal Camera</figcaption>
          </td>
        </tr>
      </table>
    </div>

    <br>

    Below is an illustration of our atmosphere model. 

    <!-- <p align="middle">
      <img src="./images/model/am.png" width="350px" />
    </p> -->

    <div align = "middle">
      <img src="./images/model/am.png" align="middle" width="400px" />
    </div>

  </p>

  <br>
  <h2 align="middle"> Volume Rendering: Technical Approach</h2>
  <p>
    The most central idea to our project is Volume Rendering, as this is how we determine the color of every pixel. We
    learned about Volume Render mostly from a series
    of online lessons provided by <a
      href="https://www.scratchapixel.com/lessons/3d-basic-rendering/volume-rendering-for-developers/intro-volume-rendering.html">Scratchapixel</a>.
  <h3> Scattering </h4>
  The atmosphere is not vacuum. It contains small air particles and aerosols, and they caused scattering effects. We
  will be focusing on 2 kinds of scattering:
  <ul>
    <li>
      Rayleigh scattering: scattering by small particles such as air particles
    </li>
    <li>
      Mie Scattering: scattering by aerosols such as dust. These molecules are generally bigger.
    </li>
  </ul> <br>
  While the sunlight is usually not directly toward our eyes, we still can see light on the sky, and this is because
  sun light is being deflected and scattered by particles
  the light encountered. These scattering effects dominated the color and intensity of light that the camera ray
  received. <br>
  Out-scattering is the main reason why in the atmosphere, as light travels, it diminishes. The amount of light that
  can pass throught the atmosphere is governed by Beer-Lamber Law, and the transmittence of that in that medium
  is \(T = e^{-distance*\sigma}\), where \(\sigma\) is the scattering coefficient of the medium. The equations for
  Rayleigh and Mie scattering can tell us this coefficient. <br>
  <br>
  For Rayleigh scattering, $$\beta(h) = \frac{8\pi^3(n^2-1)^2}{3N\lambda^4}e^{-\frac{h}{H_R}}$$ 
  \(h\) is the height
  of which we are calculating the scattering coefficient.<br>

  <br>
  For Mie scattering, $$\beta(h) = \beta(0)e^{-\frac{h}{H_M}}$$
   \(\beta(0)\) is the Mie scattering coefficient at sea
  level. \(h\) is the height of which we are calculating the scattering coefficient. <br>
  Therefore, both scattering coefficients vavaries with elevation. <br>

  <h3> Rendering the Volume</h4>
  For every pixel on the screen, we shoot a ray from the pixel, and integrate along this camera ray to obtain the
  final color of the pixel. <br>
  <figure align="middle">
    <img src="../milestone/image/simplemodel.jpg" width="400px" align="middle">
    <figcaption style="text-align: left;">We will integrate along the purple ray to obtain the final pixel of the source pixel of the purple
      ray. The outer circle is the atmosphere, and the inner circle is the earth. \(P_c\) is the position of the
      camera,
      \(P_a\) is where our camera ray hits the edge of the atmosphere, and \(P_s\) is where the sunlight hits the
      atmosphere.
    </figcaption>
  </figure>
  However, since the sun is very far away, sunlight that falls on the earth can roughly be seen as parallel light.
  Therefore, our full model looks like this: <br>
  <figure align="middle">
    <img src="../milestone/image/fullmodel.jpg" width="400px" align="middle">
    <figcaption>\(P_{si}\) are where the parallel sunlights hits the atmosphere.
    </figcaption>
  </figure>
  Therefore, at each segment of the camera ray, we have different lights fall on it, because:
  <ol>
    <li>
      Each segment will be occluded by previous segments;
    </li>
    <li>
      The amount of sunlight received by each segment is also different, as the distance that sunlight need to travel
      within the atmosphere in order to hit that segment of the camera Ray
      is different.
    </li>
  </ol>
  Therefore, to integrate along the camera ray, for each segment on
  the camera ray, we will have to calculate, how much light from the light source falls onto it. This is done by
  another integration (so we will also be integrating on the yellow lines
  in the diagram above to calculate the amount of light that reaches the intersection of yellow and purple lines). You
  might wondering why do we need to integrate along the yellow lines to
  obtain the amount of sunlight that reaches the camera ray, instead of simply calculating the transmittence with Beer
  Law and multiply it with intensity? Remember that both Rayleight and Mie scattering coefficients varies with
  elevation, and as sunlight travels, the elevation changes,
  so the transmittence of light changes as it travels. Therefore, the sunlight that reaches one segment $X$ of the
  camera ray can be expressed as: $$L_{sun}(X) = Sun\space Intensity * T(X, P_s) * P(V,L)*\beta.$$ $P(V,L)$ is the
  phase function for scattering, and it tells us about how much light is scattered for a particular viewing direction.
  It's givien by the type of scattering. We will do the integration at the end to combine the two integrals. <br>
  After obtaining the amount of light at each segment, we can sum them up to obtain the final color, taking into
  consideration that to eventually reach the camera,
  the camera ray will also travel through the atmosphere, and scattering will also occur. Therefore, the conceptual
  formula is: $$L=\int_{P_c}^{P_a} L_{sun}(X)T(P_c, X)dX,$$ and we
  substitute $L_{sun}$ into the integration. <br>
  In practice, for each segment, we shoot a ray from the segment, and divide this light source ray into another 8
  segments, and sum up their resulted light vector. Then for each segment on the camera ray,
  we multiply the sumed light vector with the distance the light will travel in one segment and the transmittence
  using the scattering coefficient at the end of the segment. (This is basically a Riemann sum along the camera ray).
  <br>
  One modification that we made is instead of assuming that the light source ray is sampled from the center of the
  segment, we assumed that the light ray is from the end of the segment, because when
  we were doing calculations, we assumed the light source ray traveled through the whole sample (the distance that the
  light will travel that we multiplied was the length of the segment), so we thought it would be more accurate to
  sample the segment at the end of it.
  <h2 align="middle"> Volume Rendering: Results</h2>
  <div align="middle">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./images/normal/skydome.0000.png" align="middle" width="170px" />
          <figcaption>Angle = 0.00</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0005.png" align="middle" width="170px" />
          <figcaption>Angle = 6.07</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0010.png" align="middle" width="170px" />
          <figcaption>Angle = 12.13</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0015.png" align="middle" width="170px" />
          <figcaption>Angle = 18.20</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0020.png" align="middle" width="170px" />
          <figcaption>Angle = 24.27</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0025.png" align="middle" width="170px" />
          <figcaption>Angle = 30.34</figcaption>
        </td>
      </tr>
      <tr align="center">
        <td>
          <img src="./images/normal/skydome.0030.png" align="middle" width="170px" />
          <figcaption>Angle = 36.40</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0035.png" align="middle" width="170px" />
          <figcaption>Angle = 42.47</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0040.png" align="middle" width="170px" />
          <figcaption>Angle = 48.54</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0045.png" align="middle" width="170px" />
          <figcaption>Angle = 54.61</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0050.png" align="middle" width="170px" />
          <figcaption>Angle = 60.67</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0055.png" align="middle" width="170px" />
          <figcaption>Angle = 66.74</figcaption>
        </td>
      </tr>
      <tr align="center">
        <td>
          <img src="./images/normal/skydome.0060.png" align="middle" width="170px" />
          <figcaption>Angle = 72.81</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0065.png" align="middle" width="170px" />
          <figcaption>Angle = 78.88</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0070.png" align="middle" width="170px" />
          <figcaption>Angle = 84.94</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0075.png" align="middle" width="170px" />
          <figcaption>Angle = 91.01</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0080.png" align="middle" width="170px" />
          <figcaption>Angle = 97.08</figcaption>
        </td>
        <td>
          <img src="./images/normal/skydome.0085.png" align="middle" width="170px" />
          <figcaption>Angle = 103.15</figcaption>
        </td>
      </tr>
    </table>
  </div>

  <br>

  <P>
    Since we've built a physical model, we can render images from different perspective by a simple change of camera position.
    Below are rendered with camera located at x = 500000, above atmosphere. 
  </P>

  <div align="middle">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./images/farawaySunset/skydome.0060 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 72.81</figcaption>
        </td>
        <td>
          <img src="./images/farawaySunset/skydome.0062 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 75.24</figcaption>
        </td>
        <td>
          <img src="./images/farawaySunset/skydome.0064 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 77.66</figcaption>
        </td>
        <td>
          <img src="./images/farawaySunset/skydome.0066 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 80.09</figcaption>
        </td>
        <td>
          <img src="./images/farawaySunset/skydome.0068 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 82.52</figcaption>
        </td>
        <td>
          <img src="./images/farawaySunset/skydome.0070 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 84.94</figcaption>
        </td>
      </tr>
      <tr align="center">
        <td>
          <img src="./images/farawaySunset/skydome.0072 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 87.37</figcaption>
        </td>
        <td>
          <img src="./images/farawaySunset/skydome.0074 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 89.80</figcaption>
        </td>
        <td>
          <img src="./images/farawaySunset/skydome.0076 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 92.22</figcaption>
        </td>
        <td>
          <img src="./images/farawaySunset/skydome.0078 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 94.65</figcaption>
        </td>
        <td>
          <img src="./images/farawaySunset/skydome.0080 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 97.08</figcaption>
        </td>
        <td>
          <img src="./images/farawaySunset/skydome.0082 Small.jpeg" align="middle" width="170px" />
          <figcaption>Angle = 99.51</figcaption>
        </td>
      </tr>
    </table>
  </div>

  <br>
  <h2 align="middle"> Tone Mapping: Technical Approach </h2>
  <p>In reality, the luminance of the sky can be arbitrarily high, with values in the range of $[0, \infty)$ at each
    point.
    However, computer screens have limited display capabilities and can only show RGB colors within the range of
    $[0, 255]$.
    As a result, any values above 255 will be clipped during rendering, resulting in a loss of detail.
    To address this problem, we use tone mapping, a mathematical technique that maps values from the high dynamic
    range (HDR) of $[0, \infty)$ to the low dynamic range (LDR) of $[0, 255]$.
    <br>
    In our project, we have experimented with several tone mapping techniques.

  <ol>
    <li> Reinhard </li>

    This is one of the simplest tone mapping operator. It is calculated as: $$L_{out} = \frac{L_{in}}{L_{in} + 1}$$

    <li> Extended Reinhard </li>

    Standard Reinhard tone mapping does not utilize the full range of our Low Dynamic Range. Extended Reinhard takes
    into account of the brightest radiance in our image and maps that value to $(1.0, 1.0, 1.0)$.
    We define the brightest luminance as $L_{white}$. Extended Reinhard tone mapping equation is as follows:
    $$L_{out} = \frac{L_{in}}{1 + \frac{L_{in}}{L_{white}^2}}$$

    <li> Extended Reinhard (Luminance Tone Mapping) </li>

    The above TMO operates on individual color channel instead of total luminance, but luminance is also an
    important part of how an image appears.
    A color value might be the same, but they will appear brighter. For example, (0.0, 1.0, 0.0), green, appears
    brigher than (0.0, 0.0, 1.0), blue.
    Luminance tone mapping a technique that takes luminance into account.
    The equation is given by: $$L_{out} = L_{in} \frac{Lum_{in}}{Lum_{out}},$$ where Lum is calculated as: $$ Lum =
    0.2126R + 0.7152G + 0.0722B$$

    <li> Uncharted Filmic Tone Mapping </li>

    The filmic tone mapping curve is another technique commonly used. It differs from reinhard TMO as it is based on
    a more complex model of human vision,
    which takes into account phenomena such as color adaptation and contrast sensitivity.

    It is calculated as follows:
    $$L_{out} = \frac{L_{in} * (A * L_{in} + C * B) + D * E}{L_{in} * (A * L_{in} + B) + D * F} - \frac{E}{F}$$
    <!-- $$L_{out} = ((L_{in} * (A * L_{in} + C * B) + D * E) / (L_{in} * (A * L_{in} + B) + D * F)) - E / F,$$ -->
    for uncharted2, the basic parameters are defined as:
    <br>
    <div id="comparisonTable">
      <table>
        <tr>
          <th>A</th>
          <th>B</th>
          <th>C</th>
          <th>D</th>
          <th>E</th>
          <th>F</th>
        </tr>
        <tr>
          <td>0.15f</td>
          <td>0.50f</td>
          <td>0.10f</td>
          <td>0.20f</td>
          <td>0.02f</td>
          <td>0.30f</td>
        </tr>

      </table>
    </div>

    <br>


    <li> Approximate ACES (Academic Color Encoding System) </li>

    This is another commonly used filmic tone mapping. We use the simplified, approximate version by Krzysztof
    Narkowicz.
    It is calculated as:
    $$L_{in} *= 0.6$$
    $$L_{out} = \frac{L_{in} * (A * L_{in} + B)}{L_{in} * (C * L_{in} + D) + E}$$
    <!-- $$L_{out} = (L_{in} * (A * L_{in} + B)) / (L_{in} * (C * L_{in} + D) + E),$$ -->

    the parameters are defined as:

    <div id="comparisonTable">
      <table>
        <tr>
          <th>A</th>
          <th>B</th>
          <th>C</th>
          <th>D</th>
          <th>E</th>
        </tr>
        <tr>
          <td>2.51f</td>
          <td>0.03f</td>
          <td>2.43f</td>
          <td>0.59f</td>
          <td>0.14f</td>
        </tr>

      </table>
    </div>

  </ol>


  <br>
  <h2 align="middle"> Tone Mapping: Results</h2>
  Here are our results, we included the image rendered with no mapping tone for reference.
  <br><br>
  Sequence 40, sun angle = 48.54.

  <div align="middle">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./images/tonemapping/notone_40.jpeg" align="middle" width="170px" />
          <figcaption>No Tone</figcaption>
        </td>
        <td>
          <img src="./images/tonemapping/reinhard_40.jpeg" align="middle" width="170px" />
          <figcaption>Reinhard</figcaption>
        </td>
        <td>
          <img src="./images/tonemapping/extended_reinhard_40.jpeg" align="middle" width="170px" />
          <figcaption>Extended Reinhard</figcaption>
        </td>
        <td>
          <img src="./images/tonemapping/extended_reinhard_lum_40.jpeg" align="middle" width="170px" />
          <figcaption>Reinhard with Lum</figcaption>
        </td>
        <td>
          <img src="./images/tonemapping/uncharted2_40.jpeg" align="middle" width="170px" />
          <figcaption>uncharted2</figcaption>
        </td>
        <td>
          <img src="./images/tonemapping/aces_approx_40.jpeg" align="middle" width="170px" />
          <figcaption>ACES approx</figcaption>
        </td>
      </tr>
    </table>
  </div>

  <br>

  Sequence 60, sun angle = 72.81.


  <div align="middle">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./images/tonemapping/notone_60.jpeg" align="middle" width="170px" />
          <figcaption>No Tone</figcaption>
        </td>
        <td>
          <img src="./images/tonemapping/reinhard_60.jpeg" align="middle" width="170px" />
          <figcaption>Reinhard</figcaption>
        </td>
        <td>
          <img src="./images/tonemapping/extended_reinhard_60.jpeg" align="middle" width="170px" />
          <figcaption>Extended Reinhard</figcaption>
        </td>
        <td>
          <img src="./images/tonemapping/extended_reinhard_lum_60.jpeg" align="middle" width="170px" />
          <figcaption>Reinhard with Lum</figcaption>
        </td>
        <td>
          <img src="./images/tonemapping/uncharted2_60.jpeg" align="middle" width="170px" />
          <figcaption>uncharted2</figcaption>
        </td>
        <td>
          <img src="./images/tonemapping/aces_approx_60.jpeg" align="middle" width="170px" />
          <figcaption>ACES approx</figcaption>
        </td>
      </tr>
    </table>
  </div>


  <br>
  ChatGPT has also given us their own tone mapping. 
  From this cartoon like gif, we are able to see the power of tone mapping. 
  Through a simple function, the appearance of an image can be dramastically changed. 
  <p style="text-align:center;"><img src="images/tonemapping/chatgptTone.gif" width="250px"></p>
  </p>




  <br>
  <h2 align="middle"> A Peak into Real-Time Rendering </h2>
  <p>

    The rendering time of our scene significantly increases as we increase the number of samples on camera ray (V)
    and/or light source ray (L),
    as well as the image size.
    Below is a comparison table highlighting the substantial increase in render time.

  <div id="comparisonTable">
    <table>
      <tr>
        <th>Width</th>
        <th>Height</th>
        <th>Num of Samples on V</th>
        <th>Num of Samples on L</th>
        <th>Average Render Time</th>
      </tr>
      <tr>
        <td>640</td>
        <td>480</td>
        <td>16</td>
        <td>8</td>
        <td>3.5593s</td>
      </tr>
      <tr>
        <td>1900</td>
        <td>1000</td>
        <td>100</td>
        <td>50</td>
        <td>323.926s</td>
      </tr>

    </table>
  </div>

  <br>

  Sky rendering is a crucial aspect of game engines,
  but as seen above, it is highly computationally expensive.
  To address this challenge, we explored various techniques to improve rendering speed.
  One common approach used in the industry is precomputing a lookup table,
  where L values are calculated in advance for each camera location and viewing direction.

  <br>

  Due to time constraints, we simplified the problem by fixing the camera location and only computing a lookup table
  for varying viewing directions.
  We create three seperate maps representing the three color channels,
  and the first three values within each map are keys to specify a viewing direction.
  Our maps for width = 1900, height = 1000, num of samples on V = 100, num of samples on L = 50, sun angle = 0
  can be found here:

  <a href="https://drive.google.com/drive/folders/1szfP8WAzTXhvdMrIRFe4Ckkb6HpCDKr2?usp=share_link"> Lookup Table</a>


  <br><br>
  <div align="middle">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./images/precompute/precompute.jpeg" align="middle" width="400px" />
          <figcaption>Normal Render</figcaption>
        </td>
        <td>
          <img src="./images/precompute/lookuptablerender.jpeg" align="middle" width="400px" />
          <figcaption>Render with lookup table</figcaption>
        </td>
      </tr>

    </table>
  </div>

  <br>

  We observed a significant improvement in rendering runtime,
  but it still falls short of real-time requirements.
  Achieving real-time rendering would require GPU parallelism or other advanced tools,
  which we were unable to implement within our project timeline.

  <br><br>

  <div id="comparisonTable">
    <table>
      <tr>
        <th>Width</th>
        <th>Height</th>
        <th>Num of Samples on V</th>
        <th>Num of Samples on L</th>
        <th>Average Render Time</th>
      </tr>
      <tr>
        <td>1900</td>
        <td>1000</td>
        <td>100</td>
        <td>50</td>
        <td>6.2582s</td>
      </tr>

    </table>
  </div>

  <br>

  </p>
  <h2 align="middle">Rainbow, or Halo?: Technical Approach</h2>
  We found a <a
    href="http://download.nvidia.com/developer/SDK/Individual_Samples/DEMOS/Direct3D9/src/HLSL_RainbowFogbow/docs/RainbowFogbow.pdf">
    guide</a> provided by
  Nvidia on rendering rainbows and other natual effects caused by waterdrops in the air. Rainbows (and Halo) is caused
  by refractions of light with different wavelength
  inside the water droplet. The color of the rainbow is determined by the angle of deviation (angle between the eye and
  the sunlight) and radius of the waterdrop. A Lee diagram
  provides a precomputed texture. With a precomputed lookup table for rainbow color, we were able to sample the lookup
  table as a texture, and blend the sampled color with the computed
  sky color. The X-axis of the lookup table is the radius of the water droplet, which we could determine based on the
  different visual effects we want, and the Y-axis
  of the lookup table is the angle between the sun direction and the view direction (our camera ray direction). <br>
  While the conceptual ideas were simple, this tutorial provided by Nvidia was intended for shaders, and the terminology
  it used were all for vertex shaders. We adapted the methods
  described in the article for a brute force calculation within our rendering function. After calculating the color of
  the pixel, we then use the camera ray projected by this pixel
  and viewing direction, and proceed to the texture map to query the color at this pixel location.<br>
  After rendering the results, we are actually a bit confused if we are rendering halo or rainbow, because halo is
  circular around
  the sun, and rainbow is more like an arch. (but it looks good either way)
  <h2 align="middle">Rainbow, or Halo?: Results</h2>
  hmm, so is this halo or rainbow?
  <div align="middle">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./images/rainbows/skydome.0020.png" align="middle" width="170px" />
          <figcaption>Angle = 24.27</figcaption>
        </td>
        <td>
          <img src="./images/rainbows/skydome.0040.png" align="middle" width="170px" />
          <figcaption>Angle = 48.54</figcaption>
        </td>
        <td>
          <img src="./images/rainbows/skydome.0050.png" align="middle" width="170px" />
          <figcaption>Angle = 60.67</figcaption>
        </td>
        <td>
          <img src="./images/rainbows/skydome.0060.png" align="middle" width="170px" />
          <figcaption>Angle = 72.81</figcaption>
        </td>
        <td>
          <img src="./images/rainbows/skydome.0070.png" align="middle" width="170px" />
          <figcaption>Angle = 84.94</figcaption>
        </td>
        <td>
          <img src="./images/rainbows/skydome.0075.png" align="middle" width="170px" />
          <figcaption>Angle = 91.01</figcaption>
        </td>
      </tr>
    </table>
  </div>
  <h2 align="middle">Problems Encountered in Implementation</h2>
  We had a LOT of troubles understanding the physics and math behind the scene, especially the integration. While it
  took a while to understanding the conceptual integration,
  it took us even longer to understand the Ray-marching algorithm described by <a
    href="https://www.scratchapixel.com/lessons/3d-basic-rendering/volume-rendering-for-developers/intro-volume-rendering.html">Scratchapixel</a>.
  We even had a <a href="https://www.notion.so/sky-rainbow-b756e5f9540344feb524788b5c53e664?pvs=4">shared page</a>
  where we write down our understanding of the tutorials and the paper. <br>
  We were also having troubles with implementing our ideas using C++. For the rainbow section, the conceptual idea
  of sampling a texture was very simple, but it took us a long time to finally load
  the texture using C++. We spent hours reading OpenCV documentation for C++ and also tried the library used by
  staff for Project 4, the <code>stb_image</code> library.
  <h2 align="middle">Lessons Learned</h2>
  Learning about the physics behind the sky was very interesting, and when we finally understood it, it was very
  fulfilling. <br>
  We also regret not using Python for the project. We used C++ because we've been using C++ throughout the semester,
  but C++ was so painful, and for the purpose of our project (simulating rays to calculate pixel color), we could
  have used Python. In addition, since
  our project was not built on top of existing class projects, we were able to directly borrow the staff code. So
  when I tried to borrow code from class projects, it took me an hour to realize that CGL was a custom
  library written by the staff, and we were NOT using OpenGL directly!

  <br>
  <h2 align="middle">Resources</h2>
<p>
    For simulating the sky:
    <ul>
        <li>
            Scratchapixel. (n.d.). Simulating colors of the sky. https://www.scratchapixel.com/lessons/procedural-generation-virtual-worlds/simulating-sky/simulating-colors-of-the-sky.html

        </li>
        <li>
          Scratchapixel. (n.d.). Volume Rendering. https://www.scratchapixel.com/lessons/3d-basic-rendering/volume-rendering-for-developers/intro-volume-rendering.html
        </li>
        <li>
            Nishita, T., Nakamae, E., Miyawaki, Y., & Shinya, M. (1993). A display method of the earth taking into account atmospheric scattering. SIGGRAPH '93 Proceedings of the 20th annual conference on Computer graphics and interactive techniques, 175-182. http://nishitalab.org/user/nis/cdrom/sig93_nis.pdf

        </li>
        <li>
            Bruneton, E., & Neyret, F. (2008). Accurate atmospheric scattering. GPU Gems 2, 175-198. https://developer.nvidia.com/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-16-accurate-atmospheric-scattering
        </li>
        <li>
            Habel, R., Kuhlen, T., & Dachsbacher, C. (2020). Real-time rendering of atmospheric phenomena using voxel cone tracing. Computer Graphics Forum, 39(4), 107-119. https://sebh.github.io/publications/egsr2020.pdf
        </li>
    </ul> 
    For the rainbow:
    <ul>
        <li>
            Bruneton, E., & Neyret, F. (2008). Accurate atmospheric scattering. GPU Gems 2, 175-198. https://developer.nvidia.com/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-16-accurate-atmospheric-scattering
        </li>
    </ul>
    For tone mapping:
    <ul>
        <li>
          Tayler,M. Tone Mapping. https://64.github.io/tonemapping/
        </li>
    </ul>

    For real time rendering:
    <ul>
        <li>
            Boubekeur, T., & Schlick, C. (2008). Efficient evaluation of functions defined by distance fields. In Proceedings of the 2008 ACM symposium on Solid and physical modeling (pp. 87-98). https://hal.inria.fr/inria-00288758/document
        </li>
    </ul>
   
    Code are in C++. 
</p>


  <h2 align="middle"> Contributions </h2>
  <p>
  Zhihan Cheng: Implemented sky rendering, tone mapping, real-time rendering, wrote final Report, recorded video <br>
  Yuerou Tang: Implemented sky rendering, rainbow, wrote final report, recorded video <br>
  Long He: Implemented sky rendering, rainbow, wrote final report, recorded video <br>
  Debby Lin: Wrote proposal <br>
  </p>


  <br>
  <h2 align="middle"> Gallery </h2>
  <!-- <p align = "center">
    <img src="./main.gif" align="middle" width="400px" />
  </p> -->

  <!-- <br> -->

  <p>
    This is what the sky could look like is only certain wavelength can be reflected.
  </p>

  <div align="middle">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./images/gallery/only440nm_50.jpeg" align="middle" width="300px" />
          <figcaption>Only 440nm Scattering</figcaption>
        </td>
        <td>
          <img src="./images/gallery/only550nm_50.jpeg" align="middle" width="300px" />
          <figcaption>Only 550nm Scattering</figcaption>
        </td>
        <td>
          <img src="./images/gallery/only680nm_50.jpeg" align="middle" width="300px" />
          <figcaption>Only 680nm Scattering</figcaption>
        </td>
      </tr>
    </table>
  </div>

  <br><br>

  <p>
    Rayleigh scattering occurs when light interacts with small particles in the atmosphere, 
    such as nitrogen and oxygen molecules. 
    This type of scattering is responsible for the blue color of the sky during the day, 
    and the red and orange colors seen during sunrise and sunset. 
    This is because shorter-wavelength blue light is scattered more than longer-wavelength red and orange light.
    <br>
    On the other hand, Mie scattering occurs when light interacts with larger particles in the atmosphere, 
    such as dust, smoke, and water droplets. 
    This type of scattering is responsible for phenomena such as haze and fog.
  </p>

  <div align="middle">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./images/gallery/only_rayleigh_50.jpeg" align="middle" width="300px" />
          <figcaption>Only Rayleigh Scattering</figcaption>
        </td>
        <td>
          <img src="./images/gallery/only_mie_50.jpeg" align="middle" width="300px" />
          <figcaption>Only Mie Scattering</figcaption>
        </td>
      </tr>
    </table>
  </div>

  <br>

  <p>
    This image of a sunset was created by stitching together 90 individual images, 
    each taken with a different sun angle. 
    The result is the view of the sun setting over the horizon. The image was not tone mapped.
  </p>
  <p align = "center">
    <img src="./main.gif" align="middle" width="450px" />
    <!-- <figcaption align="center">Sunset</figcaption> -->
  </p>

  <br>

  <p>And here's from outer space!</p>

  <p align = "center">
    <img src="./far165.gif" align="middle" width="450px" />
    <!-- <figcaption align="center">Sunset</figcaption> -->
  </p>

  <!-- <div align="middle">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./main.gif" align="middle" width="340px" />
        </td>
        <td>
          <img src="./far165.gif" align="middle" width="340px" />
        </td>
      </tr>
    </table>
  </div> -->
  

</body>

</html>